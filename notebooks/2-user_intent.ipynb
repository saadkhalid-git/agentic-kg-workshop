{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np0plMPXRvoq"
   },
   "source": [
    "# Lesson 2 - User Intent\n",
    "\n",
    "With the fundamentals of agent development with Google ADK in mind, you can start to build a workflow\n",
    "for knowledge graph construction. \n",
    "\n",
    "First things first:\n",
    "- Knowledge graph construction begins like any data modeling exercise -- the first step is to figure out motivation. \n",
    "- What do you want to do with the data?\n",
    "- This is important for normal data engineering, and critical for designing an agentic system.\n",
    "- The goal will drive everything else that happens in the workflow.\n",
    "\n",
    "Clarify the user's goal:\n",
    "- You'll want to ask two clarifying questions:\n",
    "- What kind of graph do you want to build?\n",
    "- What is the purpose of the graph?\n",
    "\n",
    "\n",
    "## Agent Details\n",
    "\n",
    "- A goal-oriented, conversational agent that helps the user ideate on the kind of graph to build.\n",
    "- Input: nothing\n",
    "- Output: `approved_user_goal`, a dictionary pairing a kind of graph with a description of the purpose of the graph.\n",
    "- Tools: `set_perceived_user_goal`, `approve_perceived_user_goal`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The usual import of needed libraries, loading of environment variables, and connection to Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbwxKypOSBkN"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MI_qvZJrSJuR"
   },
   "outputs": [],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_5 = \"openai/gpt-5\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_5)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check connection to Neo4j by sending a query\n",
    "\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAM0BqGWSTo5"
   },
   "source": [
    "---\n",
    "\n",
    "## Define the User Intent Agent (`user_intent_agent`)\n",
    "\n",
    "### agent instructions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script\n",
    "\n",
    "- user intentions set the overall direction for knowledge graph construction\n",
    "- they are so important that we will preserve them in memory so each step of the workflow is in agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_goal_definition = \"\"\"\n",
    "    A user goal has two components:\n",
    "    - kind_of_graph: at most 3 words describing the graph, for example \"social network\" or \"USA freight logistics\"\n",
    "    - description: a few sentences about the intention of the graph, for example \"A dynamic routing and delivery system for cargo.\" or \"Analysis of product dependencies and supplier alternatives.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_use_case_suggestions = \"\"\"\n",
    "    If the user is unsure what to do, make some suggestions based on classic use cases like:\n",
    "    - social network involving friends, family, or professional relationships\n",
    "    - logistics network with suppliers, customers, and partners\n",
    "    - recommendation system with customers, products, and purchase patterns\n",
    "    - fraud detection over multiple accounts with suspicious patterns of transactions\n",
    "    - pop-culture graphs with movies, books, or music\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_intent_agent_role_and_goal = \"\"\"\n",
    "    You are an expert at knowledge graph use cases. \n",
    "    Your primary goal is to help the user come up with a knowledge graph use case.\n",
    "    Knowledge graph use cases appear in all industries. Wherever there is data, there's probably a graph.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_of_thought_directions = \"\"\"\n",
    "    Think carefully and collaborate with the user:\n",
    "    1. Understand the user's goal, which is a kind_of_graph with description\n",
    "    2. Ask clarifying questions as needed\n",
    "    3. When you think you understand their goal, use the 'set_perceived_user_goal' tool to record your perception\n",
    "    4. Present the perceived user goal to the user for confirmation\n",
    "    5. If the user agrees, use the 'approve_perceived_user_goal' tool to approve the user goal. This will save the goal in state under the 'approved_user_goal' key.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the instruction components into one complete instruction...\n",
    "user_intent_agent_instruction = f\"\"\"\n",
    "{user_intent_agent_role_and_goal}\n",
    "{graph_use_case_suggestions}\n",
    "{user_goal_definition}\n",
    "{chain_of_thought_directions}\n",
    "\"\"\"\n",
    "\n",
    "print(user_intent_agent_instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define the tools for the User Intent Agent\n",
    "\n",
    "PERCEIVED_USER_GOAL = \"perceived_user_goal\"\n",
    "\n",
    "def set_perceived_user_goal(kind_of_graph: str, graph_description:str, tool_context: ToolContext):\n",
    "    \"\"\"Sets the perceived user's goal, including the kind of graph and its description.\n",
    "    \n",
    "    Args:\n",
    "        kind_of_graph: 2-3 word definition of the kind of graph, for example \"recent US patents\"\n",
    "        graph_description: a single paragraph description of the graph, summarizing the user's intent\n",
    "    \"\"\"\n",
    "    user_goal_data = {\"kind_of_graph\": kind_of_graph, \"graph_description\": graph_description}\n",
    "    tool_context.state[PERCEIVED_USER_GOAL] = user_goal_data\n",
    "    return tool_success(PERCEIVED_USER_GOAL, user_goal_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define the tools for the User Intent Agent\n",
    "\n",
    "APPROVED_USER_GOAL = \"approved_user_goal\"\n",
    "\n",
    "def approve_perceived_user_goal(tool_context: ToolContext):\n",
    "    \"\"\"Upon approval from user, will record the perceived user goal as the approved user goal.\"\"\"\n",
    "    if PERCEIVED_USER_GOAL not in tool_context.state:\n",
    "        return tool_error(\"perceived_user_goal not set. Ask the user to clarify their goal (kind of graph and description).\")\n",
    "    \n",
    "    tool_context.state[APPROVED_USER_GOAL] = tool_context.state.get(PERCEIVED_USER_GOAL)\n",
    "\n",
    "    return tool_success(APPROVED_USER_GOAL, tool_context.state[APPROVED_USER_GOAL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add the tools to a list\n",
    "user_intent_agent_tools = [set_perceived_user_goal, approve_perceived_user_goal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, construct the agent\n",
    "\n",
    "user_intent_agent = Agent(\n",
    "    name=\"user_intent_agent_v1\",\n",
    "    model=llm, # defined earlier in a variable\n",
    "    description=\"Helps the user ideate on a knowledge graph use case.\",\n",
    "    instruction=user_intent_agent_instruction,\n",
    "    tools=user_intent_agent_tools,\n",
    ")\n",
    "\n",
    "print(f\"Agent '{user_intent_agent.name}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zKGVwRkSduA"
   },
   "source": [
    "---\n",
    "\n",
    "## Interact with the Agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZJr8lbkSebH"
   },
   "outputs": [],
   "source": [
    "# Define an Agent Caller Utility\n",
    "# This will provide a simple \"call\" interface and access to the session\n",
    "\n",
    "from helper import make_agent_caller\n",
    "\n",
    "user_intent_caller = await make_agent_caller(user_intent_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEd2QhHyUKY8"
   },
   "outputs": [],
   "source": [
    "# Run the Initial Conversation\n",
    "\n",
    "session_start = await user_intent_caller.get_session()\n",
    "print(f\"Session Start: {session_start.state}\")\n",
    "\n",
    "# We need an async function to await our interaction helper\n",
    "async def run_conversation():\n",
    "    await user_intent_caller.call(\"I'd like a bill of materials graph (BOM graph) which includes all levels from suppliers to finished product, which can illustrate supply chain analysis.\", True)\n",
    "    # Presume approval\n",
    "    await user_intent_caller.call(\"Approve that goal.\", True)\n",
    "\n",
    "await run_conversation()\n",
    "\n",
    "session_end = await user_intent_caller.get_session()\n",
    "\n",
    "print(f\"\\nSession End...\")\n",
    "\n",
    "\n",
    "session_end = await user_intent_caller.get_session()\n",
    "\n",
    "print(f\"Session Start: {session_end.state}\")\n",
    "\n",
    "print(f\"\\nPerceived goal:\", session_end.state[PERCEIVED_USER_GOAL])\n",
    "\n",
    "print(f\"\\nApproved goal:\", session_end.state[APPROVED_USER_GOAL])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbUzAGvsmB2a"
   },
   "source": [
    "---\n",
    "\n",
    "Congratulations\\! You've created a basic human-in-the-loop interaction, with a structured result.\n",
    "\n",
    "Take a close look at the session state.\n",
    "\n",
    "- session state starts empty, as you'd expect since we did not initialize it\n",
    "- after the conversation, there are two values in session state: `perceived_user_goal` and `approved_user_goal`\n",
    "- this duplication is intentional, separating \"working memory\" from work specification\n",
    "- subsequent steps in the workflow should only use work specifications\n",
    "- in production, work specifications should be persisted to enable tracing and reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus, An Interactive Conversation\n",
    "\n",
    "Now, let's make this interactive so you can ask your own questions! Run the cell below. It will prompt you to enter your queries directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_interactive_conversation():\n",
    "    while True:\n",
    "        user_query = input(\"Ask me something (or type 'exit' to quit): \")\n",
    "        if user_query.lower() == 'exit':\n",
    "            break\n",
    "        response = await user_intent_caller.call(user_query, True)\n",
    "        print(f\"Response: {response}\")\n",
    "\n",
    "# Execute the interactive conversation\n",
    "await run_interactive_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
