{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modular LangChain GraphRAG Pipeline\n",
    "\n",
    "This notebook demonstrates the complete knowledge graph construction and Q&A system using modular agents:\n",
    "- **StructuredDataAgent**: Constructs domain graph from CSV files\n",
    "- **UnstructuredDataAgent**: Extracts entities from markdown reviews\n",
    "- **EntityResolutionAgent**: Connects subject and domain graphs\n",
    "- **LangChainRAGAgent**: Implements multiple retrieval strategies\n",
    "- **SupplyChainQASystem**: Orchestrates the complete pipeline\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "CSV Files â†’ StructuredDataAgent â†’ Domain Graph\n",
    "                                        â†“\n",
    "                              EntityResolutionAgent â†’ Connected Graph â†’ LangChainRAGAgent â†’ Q&A\n",
    "                                        â†‘\n",
    "Markdown Files â†’ UnstructuredDataAgent â†’ Subject Graph\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment Check:\n",
      "  Neo4j URI: bolt://localhost:7687\n",
      "  Neo4j Username: neo4j\n",
      "  OpenAI API Key: Set\n",
      "  Neo4j Import Dir: /var/lib/neo4j/import\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import asyncio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Import the main orchestrator\n",
    "from supply_chain_qa_system import SupplyChainQASystem, create_and_build_system\n",
    "\n",
    "# Verify environment\n",
    "print(\"âœ… Environment Check:\")\n",
    "print(f\"  Neo4j URI: {os.getenv('NEO4J_URI', 'Not set')}\")\n",
    "print(f\"  Neo4j Username: {os.getenv('NEO4J_USERNAME', 'Not set')}\")\n",
    "print(f\"  OpenAI API Key: {'Set' if os.getenv('OPENAI_API_KEY') else 'Not set'}\")\n",
    "print(f\"  Neo4j Import Dir: {os.getenv('NEO4J_IMPORT_DIR', 'Not set')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Supply Chain Q&A System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'omit' from 'openai._types' (/opt/homebrew/Caskroom/miniconda/base/envs/kg-workshop/lib/python3.12/site-packages/openai/_types.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create the system instance\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m system = \u001b[43mSupplyChainQASystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… System initialized with agents:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msystem.structured_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msystem.structured_agent.description\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agentic-kg-workshop/notebooks/supply_chain_qa_system.py:65\u001b[39m, in \u001b[36mSupplyChainQASystem.__init__\u001b[39m\u001b[34m(self, neo4j_uri, neo4j_username, neo4j_password, openai_api_key, import_dir)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m.unstructured_agent = UnstructuredDataAgent()\n\u001b[32m     64\u001b[39m \u001b[38;5;28mself\u001b[39m.resolution_agent = EntityResolutionAgent()\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28mself\u001b[39m.rag_agent = \u001b[43mLangChainRAGAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mneo4j_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mneo4j_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mneo4j_username\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mneo4j_username\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mneo4j_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mneo4j_password\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Configuration\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mself\u001b[39m.construction_plan = DEFAULT_SUPPLY_CHAIN_PLAN\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/agentic-kg-workshop/notebooks/langchain_rag_agent.py:64\u001b[39m, in \u001b[36mLangChainRAGAgent.__init__\u001b[39m\u001b[34m(self, neo4j_uri, neo4j_username, neo4j_password, openai_model, embedding_model, temperature)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28mself\u001b[39m.graph = Neo4jGraph(\n\u001b[32m     57\u001b[39m     url=neo4j_uri,\n\u001b[32m     58\u001b[39m     username=neo4j_username,\n\u001b[32m     59\u001b[39m     password=neo4j_password,\n\u001b[32m     60\u001b[39m     database=\u001b[33m\"\u001b[39m\u001b[33mneo4j\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m )\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Initialize LLM and embeddings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28mself\u001b[39m.llm = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopenai_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mself\u001b[39m.embeddings = OpenAIEmbeddings(model=embedding_model)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Initialize vector store (will be set up later)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/kg-workshop/lib/python3.12/site-packages/langchain_core/load/serializable.py:115\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/kg-workshop/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:826\u001b[39m, in \u001b[36mBaseChatOpenAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    821\u001b[39m     sync_specific = {\n\u001b[32m    822\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_client\n\u001b[32m    823\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_httpx_client(\u001b[38;5;28mself\u001b[39m.openai_api_base, \u001b[38;5;28mself\u001b[39m.request_timeout)\n\u001b[32m    824\u001b[39m     }\n\u001b[32m    825\u001b[39m     \u001b[38;5;28mself\u001b[39m.root_client = openai.OpenAI(**client_params, **sync_specific)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m826\u001b[39m     \u001b[38;5;28mself\u001b[39m.client = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m.completions\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_client:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.openai_proxy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.http_async_client:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/kg-workshop/lib/python3.12/functools.py:998\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m    996\u001b[39m val = cache.get(\u001b[38;5;28mself\u001b[39m.attrname, _NOT_FOUND)\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    999\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1000\u001b[39m         cache[\u001b[38;5;28mself\u001b[39m.attrname] = val\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/kg-workshop/lib/python3.12/site-packages/openai/_client.py:175\u001b[39m, in \u001b[36mchat\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    164\u001b[39m     base_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    167\u001b[39m     version=__version__,\n\u001b[32m    168\u001b[39m     base_url=base_url,\n\u001b[32m    169\u001b[39m     max_retries=max_retries,\n\u001b[32m    170\u001b[39m     timeout=timeout,\n\u001b[32m    171\u001b[39m     http_client=http_client,\n\u001b[32m    172\u001b[39m     custom_headers=default_headers,\n\u001b[32m    173\u001b[39m     custom_query=default_query,\n\u001b[32m    174\u001b[39m     _strict_response_validation=_strict_response_validation,\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m )\n\u001b[32m    177\u001b[39m \u001b[38;5;28mself\u001b[39m._default_stream_cls = Stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/kg-workshop/lib/python3.12/site-packages/openai/resources/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbeta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     Beta,\n\u001b[32m      5\u001b[39m     AsyncBeta,\n\u001b[32m      6\u001b[39m     BetaWithRawResponse,\n\u001b[32m      7\u001b[39m     AsyncBetaWithRawResponse,\n\u001b[32m      8\u001b[39m     BetaWithStreamingResponse,\n\u001b[32m      9\u001b[39m     AsyncBetaWithStreamingResponse,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     Chat,\n\u001b[32m     13\u001b[39m     AsyncChat,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     AsyncChatWithStreamingResponse,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     Audio,\n\u001b[32m     21\u001b[39m     AsyncAudio,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     AsyncAudioWithStreamingResponse,\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/kg-workshop/lib/python3.12/site-packages/openai/resources/beta/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbeta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     Beta,\n\u001b[32m      5\u001b[39m     AsyncBeta,\n\u001b[32m      6\u001b[39m     BetaWithRawResponse,\n\u001b[32m      7\u001b[39m     AsyncBetaWithRawResponse,\n\u001b[32m      8\u001b[39m     BetaWithStreamingResponse,\n\u001b[32m      9\u001b[39m     AsyncBetaWithStreamingResponse,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchatkit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     ChatKit,\n\u001b[32m     13\u001b[39m     AsyncChatKit,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     AsyncChatKitWithStreamingResponse,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mthreads\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     Threads,\n\u001b[32m     21\u001b[39m     AsyncThreads,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     AsyncThreadsWithStreamingResponse,\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/kg-workshop/lib/python3.12/site-packages/openai/resources/beta/beta.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01massistants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     Assistants,\n\u001b[32m      8\u001b[39m     AsyncAssistants,\n\u001b[32m      9\u001b[39m     AssistantsWithRawResponse,\n\u001b[32m     10\u001b[39m     AsyncAssistantsWithRawResponse,\n\u001b[32m     11\u001b[39m     AssistantsWithStreamingResponse,\n\u001b[32m     12\u001b[39m     AsyncAssistantsWithStreamingResponse,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_resource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SyncAPIResource, AsyncAPIResource\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchatkit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchatkit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     ChatKit,\n\u001b[32m     17\u001b[39m     AsyncChatKit,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     AsyncChatKitWithStreamingResponse,\n\u001b[32m     22\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/kg-workshop/lib/python3.12/site-packages/openai/resources/beta/assistants.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpx\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _legacy_response\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Body, Omit, Query, Headers, NotGiven, omit, not_given\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m maybe_transform, async_maybe_transform\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_property\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'omit' from 'openai._types' (/opt/homebrew/Caskroom/miniconda/base/envs/kg-workshop/lib/python3.12/site-packages/openai/_types.py)"
     ]
    }
   ],
   "source": [
    "# Create the system instance\n",
    "system = SupplyChainQASystem()\n",
    "\n",
    "print(\"âœ… System initialized with agents:\")\n",
    "print(f\"  - {system.structured_agent.name}: {system.structured_agent.description}\")\n",
    "print(f\"  - {system.unstructured_agent.name}: {system.unstructured_agent.description}\")\n",
    "print(f\"  - {system.resolution_agent.name}: {system.resolution_agent.description}\")\n",
    "print(f\"  - {system.rag_agent.name}: {system.rag_agent.description}\")\n",
    "\n",
    "print(\"\\nðŸ“ Files to process:\")\n",
    "print(f\"  CSV files: {len(system.csv_files)}\")\n",
    "print(f\"  Markdown files: {len(system.markdown_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the Complete Knowledge Graph\n",
    "\n",
    "This section runs the complete pipeline:\n",
    "1. Reset the graph (optional)\n",
    "2. Build domain graph from CSVs\n",
    "3. Build subject graph from markdown reviews\n",
    "4. Perform entity resolution\n",
    "5. Initialize RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the complete knowledge graph\n",
    "# Note: Set limit_markdown_files=None to process all files (takes longer)\n",
    "results = await system.build_complete_graph(\n",
    "    reset=True,  # Reset the graph first\n",
    "    limit_markdown_files=3  # Process only 3 markdown files for demo\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Knowledge Graph Built Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the Q&A System\n",
    "\n",
    "Now let's test the system with various types of queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Simple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a simple product query\n",
    "question = \"What products are available and their prices?\"\n",
    "answer = system.ask_question(question)\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a supplier query\n",
    "question = \"List all suppliers and where they are located\"\n",
    "answer = system.ask_question(question)\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Supply Chain Tracing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test supply chain tracing\n",
    "question = \"Which suppliers provide parts for the Uppsala Sofa?\"\n",
    "answer = system.ask_question(question)\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test root cause analysis\n",
    "question = \"Trace any quality issues in furniture back to their suppliers\"\n",
    "answer = system.ask_question(question, use_workflow=True)  # Use workflow for complex query\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Review-based Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test review extraction\n",
    "question = \"What quality issues are mentioned in product reviews?\"\n",
    "answer = system.ask_question(question)\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test feature extraction\n",
    "question = \"What features do customers appreciate in the furniture products?\"\n",
    "answer = system.ask_question(question)\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore Individual Agents\n",
    "\n",
    "Let's explore what each agent can do individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Structured Data Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get domain graph statistics\n",
    "from structured_data_agent import StructuredDataAgent\n",
    "\n",
    "structured_agent = StructuredDataAgent()\n",
    "stats = structured_agent.get_graph_statistics()\n",
    "\n",
    "print(\"ðŸ“Š Domain Graph Statistics:\")\n",
    "print(\"\\nNodes:\")\n",
    "for label, count in stats['nodes'].items():\n",
    "    print(f\"  {label}: {count}\")\n",
    "\n",
    "print(\"\\nRelationships:\")\n",
    "for rel_type, count in stats['relationships'].items():\n",
    "    print(f\"  {rel_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Unstructured Data Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subject graph statistics\n",
    "from unstructured_data_agent import UnstructuredDataAgent\n",
    "\n",
    "unstructured_agent = UnstructuredDataAgent()\n",
    "stats = unstructured_agent.get_graph_statistics()\n",
    "\n",
    "print(\"ðŸ“„ Subject Graph Statistics:\")\n",
    "print(f\"\\nDocuments: {stats['document_count']}\")\n",
    "print(f\"Chunks: {stats['chunk_count']}\")\n",
    "\n",
    "print(\"\\nEntities by type:\")\n",
    "for entity_type, count in stats['entities_by_type'].items():\n",
    "    print(f\"  {entity_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Entity Resolution Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get resolution statistics\n",
    "from entity_resolution_agent import EntityResolutionAgent\n",
    "\n",
    "resolution_agent = EntityResolutionAgent()\n",
    "stats = resolution_agent.get_resolution_statistics()\n",
    "\n",
    "print(\"ðŸ”— Entity Resolution Statistics:\")\n",
    "print(f\"\\nTotal correspondences: {stats['total_correspondences']}\")\n",
    "\n",
    "print(\"\\nResolution by type:\")\n",
    "for entity_type, type_stats in stats['resolution_by_type'].items():\n",
    "    print(f\"  {entity_type}:\")\n",
    "    print(f\"    Count: {type_stats['count']}\")\n",
    "    print(f\"    Avg similarity: {type_stats['avg_similarity']}\")\n",
    "\n",
    "if stats.get('unresolved_by_type'):\n",
    "    print(\"\\nUnresolved entities:\")\n",
    "    for entity_type, count in stats['unresolved_by_type'].items():\n",
    "        print(f\"  {entity_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 LangGraph Workflow for Complex Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and test the LangGraph workflow\n",
    "workflow = system.rag_agent.create_langgraph_workflow()\n",
    "\n",
    "# Test with a complex multi-hop query\n",
    "complex_query = \"Find all quality issues in products and trace them back to the responsible suppliers through the supply chain\"\n",
    "\n",
    "print(f\"Complex Query: {complex_query}\\n\")\n",
    "print(\"Processing with LangGraph workflow...\\n\")\n",
    "\n",
    "result = workflow.invoke({\"question\": complex_query})\n",
    "\n",
    "print(f\"Query Type Detected: {result['query_type']}\")\n",
    "print(f\"\\nAnswer:\\n{result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Direct RAG Agent Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test hybrid search directly\n",
    "query = \"quality issues\"\n",
    "docs = system.rag_agent.hybrid_search(query, k=2)\n",
    "\n",
    "print(f\"Hybrid Search for: '{query}'\\n\")\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"  Content: {doc.page_content[:200]}...\")\n",
    "    if doc.metadata:\n",
    "        print(f\"  Metadata: {doc.metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test direct Cypher query generation\n",
    "question = \"How many suppliers are there in each country?\"\n",
    "cypher_result = system.rag_agent.cypher_query(question)\n",
    "\n",
    "print(f\"Cypher Query for: '{question}'\\n\")\n",
    "print(f\"Result: {cypher_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test supply chain tracing\n",
    "trace_result = system.rag_agent.trace_issue_to_supplier(\n",
    "    product_name=\"Sofa\",\n",
    "    issue_keyword=\"quality\"\n",
    ")\n",
    "\n",
    "print(\"Supply Chain Trace for Sofa with quality issues:\\n\")\n",
    "print(trace_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Q&A Session\n",
    "\n",
    "Run an interactive session where you can ask questions directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run interactive Q&A (uncomment to use)\n",
    "# system.interactive_qa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. System Test Suite\n",
    "\n",
    "Run a comprehensive test of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the system test suite\n",
    "system.test_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick Setup Function\n",
    "\n",
    "For quick demonstrations, use the convenience function that builds everything in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick setup - builds complete system with defaults\n",
    "# quick_system = await create_and_build_system(\n",
    "#     reset=True,\n",
    "#     limit_markdown_files=3\n",
    "# )\n",
    "\n",
    "# # Now you can immediately ask questions\n",
    "# answer = quick_system.ask_question(\"What suppliers are in Sweden?\")\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualization Helpers\n",
    "\n",
    "Generate Cypher queries for visualization in Neo4j Browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate visualization query for a product's supply chain\n",
    "product_name = \"Uppsala Sofa\"\n",
    "\n",
    "viz_query = f\"\"\"\n",
    "// Visualization for {product_name} supply chain\n",
    "MATCH path = (p:Product {{product_name: '{product_name}'}})-[:Contains]->(a:Assembly)\n",
    "OPTIONAL MATCH parts_path = (part:Part)-[:Is_Part_Of]->(a)\n",
    "OPTIONAL MATCH supplier_path = (part)-[:Supplied_By]->(s:Supplier)\n",
    "OPTIONAL MATCH entity_path = (e:`__Entity__`:Product)-[:CORRESPONDS_TO]->(p)\n",
    "OPTIONAL MATCH issue_path = (e)-[:HAS_ISSUE]->(issue:Issue)\n",
    "\n",
    "RETURN path, parts_path, supplier_path, entity_path, issue_path\n",
    "LIMIT 50\n",
    "\"\"\"\n",
    "\n",
    "print(f\"To visualize {product_name} in Neo4j Browser, run:\")\n",
    "print(\"\\n\" + viz_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate query to see all entity correspondences\n",
    "correspondence_query = \"\"\"\n",
    "// Show entity resolution connections\n",
    "MATCH (e:`__Entity__`)-[r:CORRESPONDS_TO]->(d)\n",
    "RETURN e, r, d\n",
    "LIMIT 25\n",
    "\"\"\"\n",
    "\n",
    "print(\"To visualize entity resolutions in Neo4j Browser:\")\n",
    "print(\"\\n\" + correspondence_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Modular Architecture**: Clean separation of concerns with specialized agents\n",
    "2. **Complete Pipeline**: From raw data to working Q&A system\n",
    "3. **Multiple Retrieval Strategies**: Vector search, Cypher queries, and graph traversal\n",
    "4. **Supply Chain Analysis**: Tracing issues through the complete supply chain\n",
    "5. **Entity Resolution**: Connecting extracted entities to domain nodes\n",
    "6. **LangGraph Workflow**: Intelligent query routing for complex questions\n",
    "\n",
    "### Key Advantages of Modular Design:\n",
    "\n",
    "- **Maintainability**: Each agent can be updated independently\n",
    "- **Testability**: Individual components can be tested in isolation\n",
    "- **Extensibility**: New agents can be added without modifying existing code\n",
    "- **Reusability**: Agents can be reused in different pipelines\n",
    "- **Clarity**: Clear responsibility boundaries between components\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Process all markdown files (remove limit)\n",
    "2. Add more entity types and relationships\n",
    "3. Implement custom similarity metrics for entity resolution\n",
    "4. Add evaluation metrics for Q&A quality\n",
    "5. Deploy as API service\n",
    "6. Create a web interface for the Q&A system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
